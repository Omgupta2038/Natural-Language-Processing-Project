# -*- coding: utf-8 -*-
"""XLNEt.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gxlVmRHVkkqFUvccqX4PozF7K4KbcUDT
"""

import os
os.environ["WANDB_DISABLED"] = "true"

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
import re
from transformers import XLNetTokenizer
from datasets import Dataset

# Combine the datasets
fake_df = pd.read_csv('/content/drive/MyDrive/ColabData/Fake.csv')
true_df = pd.read_csv('/content/drive/MyDrive/ColabData/True.csv')
fake_df['label'] = 0
true_df['label'] = 1

# Select a subset of the data for quicker processing
fake_df = fake_df.sample(2000)
true_df = true_df.sample(2000)

df = pd.concat([fake_df, true_df]).reset_index(drop=True)

# Preprocess the text
def preprocess_text(text):
    text = re.sub(r'\W', ' ', text)  # Remove all non-word characters
    text = re.sub(r'\s+', ' ', text)  # Replace multiple spaces with a single space
    text = text.lower()  # Convert to lowercase
    return text

df['text'] = df['text'].apply(preprocess_text)

# Encode labels
le = LabelEncoder()
df['label'] = le.fit_transform(df['label'])

# Split the data
X_train, X_val, y_train, y_val = train_test_split(df['text'], df['label'], test_size=0.2, random_state=42, stratify=df['label'])

# Tokenize the data
tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')

train_texts = X_train.tolist()
val_texts = X_val.tolist()

train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=512)
val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=512)

train_dataset = Dataset.from_dict({
    'input_ids': train_encodings['input_ids'],
    'attention_mask': train_encodings['attention_mask'],
    'labels': y_train.tolist()
})

val_dataset = Dataset.from_dict({
    'input_ids': val_encodings['input_ids'],
    'attention_mask': val_encodings['attention_mask'],
    'labels': y_val.tolist()
})

import transformers
print(transformers.__version__)

!pip install -U transformers

import transformers
print(transformers.__version__)

from transformers import XLNetTokenizer, XLNetForSequenceClassification, Trainer, TrainingArguments
import os

os.environ["WANDB_DISABLED"] = "true"

tokenizer = XLNetTokenizer.from_pretrained("xlnet-base-cased")
model = XLNetForSequenceClassification.from_pretrained("xlnet-base-cased", num_labels=2)

training_args = TrainingArguments(
    output_dir="./results",
    num_train_epochs=3,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    warmup_steps=500,
    weight_decay=0.01,
    logging_dir="./logs",
    logging_steps=10,
    eval_strategy="epoch",      # <- Required
    save_strategy="epoch",            # <- Must match eval strategy
    load_best_model_at_end=True,
    metric_for_best_model="eval_loss",
    greater_is_better=False
)



# Initialize Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset,
    tokenizer=tokenizer
)

# Train the model
trainer.train()

import numpy as np
from sklearn.metrics import classification_report, confusion_matrix

# Evaluate the model
predictions = trainer.predict(val_dataset)
preds = np.argmax(predictions.predictions, axis=-1)

# Classification report and confusion matrix
class_report = classification_report(y_val, preds, target_names=['Fake', 'True'])
conf_matrix = confusion_matrix(y_val, preds)

print("Classification Report:\n", class_report)
print("Confusion Matrix:\n", conf_matrix)

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# Define the confusion matrix
conf_matrix = np.array([[400, 0],
                        [1, 399]])

# Create a heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False,
            xticklabels=['Predicted Negative', 'Predicted Positive'],
            yticklabels=['Actual Negative', 'Actual Positive'])

# Set labels and title
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')

# Show the plot
plt.show()

# Save the model and tokenizer
model.save_pretrained('./saved_model')
tokenizer.save_pretrained('./saved_model')

# Save evaluation metrics
with open('./saved_model/classification_report.txt', 'w') as f:
    f.write(class_report)

np.save('./saved_model/confusion_matrix.npy', conf_matrix)

import os
import torch
from transformers import XLNetTokenizer, XLNetForSequenceClassification

# Load the saved model and tokenizer
model_path = './saved_model'
tokenizer = XLNetTokenizer.from_pretrained(model_path)
model = XLNetForSequenceClassification.from_pretrained(model_path)

# Ensure the model is in evaluation mode
model.eval()

# Define a function to preprocess the input text
def preprocess_text(text):
    text = re.sub(r'\W', ' ', text)  # Remove all non-word characters
    text = re.sub(r'\s+', ' ', text)  # Replace multiple spaces with a single space
    text = text.lower()  # Convert to lowercase
    return text

# Define a function to predict the label of a single input text
def predict(text):
    # Preprocess the text
    preprocessed_text = preprocess_text(text)

    # Tokenize the text
    inputs = tokenizer(preprocessed_text, return_tensors='pt', truncation=True, padding=True, max_length=512)

    # Make prediction
    with torch.no_grad():
        outputs = model(**inputs)
        logits = outputs.logits
        predicted_class_id = torch.argmax(logits, dim=-1).item()

    # Map the predicted class id to the label
    label_map = {0: 'Fake', 1: 'True'}
    predicted_label = label_map[predicted_class_id]

    return predicted_label

# Example input text
input_text = "This is an example input text to classify."

# Get the prediction
predicted_label = predict(input_text)

print(f"The predicted label for the input text is: {predicted_label}")

import os
import torch
import re
from transformers import XLNetTokenizer, XLNetForSequenceClassification
import shap
import numpy as np

# Load the saved model and tokenizer
model_path = './saved_model'
tokenizer = XLNetTokenizer.from_pretrained(model_path)
model = XLNetForSequenceClassification.from_pretrained(model_path)

# Ensure the model is in evaluation mode
model.eval()

# Define a function to preprocess the input text
def preprocess_text(text):
    text = re.sub(r'\W', ' ', text)  # Remove all non-word characters
    text = re.sub(r'\s+', ' ', text)  # Replace multiple spaces with a single space
    text = text.lower()  # Convert to lowercase
    return text

# Define a function to tokenize and pad the text
def tokenize_and_pad(texts):
    tokenized_texts = [tokenizer(preprocess_text(text), return_tensors='pt', truncation=True, padding='max_length', max_length=512) for text in texts]
    input_ids = torch.cat([t['input_ids'] for t in tokenized_texts], dim=0)
    attention_masks = torch.cat([t['attention_mask'] for t in tokenized_texts], dim=0)
    return {'input_ids': input_ids, 'attention_mask': attention_masks}

# Define a custom prediction function for SHAP
def custom_predict(texts):
    inputs = tokenize_and_pad(texts)
    with torch.no_grad():
        outputs = model(**inputs)
        return torch.nn.functional.softmax(outputs.logits, dim=1).cpu().numpy()

# Example input text
input_text = "This is an example input text to classify."

# Tokenize the input text
tokenized_input = tokenize_and_pad([input_text])

# Predict the label
with torch.no_grad():
    outputs = model(**tokenized_input)
    prediction = torch.argmax(outputs.logits, dim=1).cpu().numpy()[0]
    predicted_label = 'True' if prediction == 1 else 'Fake'
    print(f"The predicted label for the input text is: {predicted_label}")

# Wrap the model to work with SHAP
class WrappedModel:
    def __init__(self, model):
        self.model = model

    def predict(self, texts):
        inputs = tokenize_and_pad(texts)
        with torch.no_grad():
            outputs = self.model(**inputs)
            return torch.nn.functional.softmax(outputs.logits, dim=1).cpu().numpy()

wrapped_model = WrappedModel(model)

# Prepare the masker
masker = shap.maskers.Text(tokenizer)

# Use SHAP to explain the prediction
explainer = shap.Explainer(wrapped_model.predict, masker)

# Explain the prediction
shap_values = explainer([input_text])

# Plot the explanation
shap.plots.text(shap_values[0])

import os
import torch
import re
from transformers import XLNetTokenizer, XLNetForSequenceClassification
import shap
import numpy as np

# Load the saved model and tokenizer
model_path = './saved_model'
tokenizer = XLNetTokenizer.from_pretrained(model_path)
model = XLNetForSequenceClassification.from_pretrained(model_path)

# Ensure the model is in evaluation mode
model.eval()

# Define a function to preprocess the input text
def preprocess_text(text):
    text = re.sub(r'\W', ' ', text)  # Remove all non-word characters
    text = re.sub(r'\s+', ' ', text)  # Replace multiple spaces with a single space
    text = text.lower()  # Convert to lowercase
    return text

# Define a function to tokenize and pad the text
def tokenize_and_pad(texts):
    tokenized_texts = [tokenizer(preprocess_text(text), return_tensors='pt', truncation=True, padding='max_length', max_length=128) for text in texts]
    input_ids = torch.cat([t['input_ids'] for t in tokenized_texts], dim=0)
    attention_masks = torch.cat([t['attention_mask'] for t in tokenized_texts], dim=0)
    return {'input_ids': input_ids, 'attention_mask': attention_masks}

# Define a custom prediction function for SHAP
def custom_predict(texts):
    inputs = tokenize_and_pad(texts)
    with torch.no_grad():
        outputs = model(**inputs)
        return torch.nn.functional.softmax(outputs.logits, dim=1).cpu().numpy()

# Example input text
input_text = "Donald Trump spent a good portion of his day at his golf club, marking the 84th day he s done so since taking the oath of office. It must have been a bad game because just "

# Tokenize the input text
tokenized_input = tokenize_and_pad([input_text])

# Predict the label
with torch.no_grad():
    outputs = model(**tokenized_input)
    prediction = torch.argmax(outputs.logits, dim=1).cpu().numpy()[0]
    predicted_label = 'True' if prediction == 1 else 'Fake'
    print(f"The predicted label for the input text is: {predicted_label}")

# Wrap the model to work with SHAP
class WrappedModel:
    def __init__(self, model):
        self.model = model

    def predict(self, texts):
        inputs = tokenize_and_pad(texts)
        with torch.no_grad():
            outputs = self.model(**inputs)
            return torch.nn.functional.softmax(outputs.logits, dim=1).cpu().numpy()

wrapped_model = WrappedModel(model)

# Prepare the masker
masker = shap.maskers.Text(tokenizer)

# Use SHAP to explain the prediction
explainer = shap.Explainer(wrapped_model.predict, masker, algorithm="partition")

# Explain the prediction
shap_values = explainer([input_text], max_evals=500)

# Plot the explanation
shap.plots.text(shap_values[0])

import matplotlib.pyplot as plt
import io
import base64

# Generate a plot
def create_plot():
    plt.figure(figsize=(6, 4))
    x = [1, 2, 3, 4, 5]
    y = [2, 3, 5, 7, 11]
    plt.plot(x, y, marker='o')
    plt.title('Sample Plot')
    plt.xlabel('X-axis')
    plt.ylabel('Y-axis')

# Save the plot to a BytesIO object
def get_base64_plot():
    buffer = io.BytesIO()
    create_plot()
    plt.savefig(buffer, format='png')
    plt.close()
    buffer.seek(0)

    # Encode the plot in Base64
    img_base64 = base64.b64encode(buffer.read()).decode('utf-8')
    return img_base64

# Generate the Base64-encoded image
img_base64 = get_base64_plot()

# Create an HTML file to display the image
html_content = f"""
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Plot Display</title>
</head>
<body>
    <h1>Plot Display</h1>
    <img src="data:image/png;base64,{img_base64}" alt="Plot">
</body>
</html>
"""

# Save the HTML content to a file
with open('plot_display.html', 'w') as f:
    f.write(html_content)

print("HTML file 'plot_display.html' has been created successfully.")

