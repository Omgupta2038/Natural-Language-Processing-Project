# -*- coding: utf-8 -*-
"""Hybrid model(CNN+Fasttext).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Q1GrrSerge9eUh6qk0RwXZD1fq8TNBn3
"""

pip install pandas scikit-learn fasttext tensorflow

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

# Load datasets



fake_df = pd.read_csv('/content/drive/MyDrive/ColabData/Fake.csv')
true_df = pd.read_csv('/content/drive/MyDrive/ColabData/True.csv')


# Add labels
fake_df['label'] = 0
true_df['label'] = 1

# Combine datasets
df = pd.concat([fake_df, true_df]).reset_index(drop=True)

# Shuffle the dataset
df = df.sample(frac=1).reset_index(drop=True)

# Split into training and test sets
X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.2, random_state=42)

# Convert labels to categorical if necessary
label_encoder = LabelEncoder()
y_train = label_encoder.fit_transform(y_train)
y_test = label_encoder.transform(y_test)

import fasttext

# Prepare text data for FastText
with open('train.txt', 'w') as f:
    for text, label in zip(X_train, y_train):
        f.write(f'__label__{label} {text}\n')

with open('test.txt', 'w') as f:
    for text, label in zip(X_test, y_test):
        f.write(f'__label__{label} {text}\n')

# Train FastText model
model = fasttext.train_supervised(input='train.txt', label='__label__')

model.save_model('fasttext_model.bin')

import numpy as np

def get_fasttext_embeddings(texts, model):
    embeddings = [model.get_sentence_vector(text) for text in texts]
    return np.array(embeddings)

# Load FastText model
ft_model = fasttext.load_model('fasttext_model.bin')

# Get embeddings
X_train_embeddings = get_fasttext_embeddings(X_train, ft_model)
X_test_embeddings = get_fasttext_embeddings(X_test, ft_model)

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout

# Define CNN model
def create_cnn_model(input_shape):
    model = Sequential([
        Conv1D(filters=64, kernel_size=5, activation='relu', input_shape=input_shape),
        MaxPooling1D(pool_size=2),
        Conv1D(filters=128, kernel_size=5, activation='relu'),
        MaxPooling1D(pool_size=2),
        Flatten(),
        Dense(128, activation='relu'),
        Dropout(0.5),
        Dense(2, activation='softmax')
    ])
    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
    return model

# Create and train model
input_shape = (X_train_embeddings.shape[1], 1)
model_cnn = create_cnn_model(input_shape)
X_train_embeddings = np.expand_dims(X_train_embeddings, axis=2)
X_test_embeddings = np.expand_dims(X_test_embeddings, axis=2)

model_cnn.fit(X_train_embeddings, y_train, epochs=5, batch_size=32, validation_split=0.1)

from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Evaluate model
y_pred = model_cnn.predict(X_test_embeddings)
y_pred_classes = np.argmax(y_pred, axis=1)

# Calculate metrics
accuracy = accuracy_score(y_test, y_pred_classes)
conf_matrix = confusion_matrix(y_test, y_pred_classes)
class_report = classification_report(y_test, y_pred_classes)

print(f'Accuracy: {accuracy:.4f}')
print(f'Classification Report:\n{class_report}')

# Plot confusion matrix
plt.figure(figsize=(10, 7))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

# Save the CNN model
model_cnn.save('cnn_model.h5')



